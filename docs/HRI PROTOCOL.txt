SERVIDOR => CLIENTE
Respuestas a prompts con ID: 
{
    type: "RESPONSE",
    data: {
        id: uuid,
        method: str,
        intent: str,
        arguments: {
            arg1: value1
            arg2: value2
            ...
        }
        provider: str,
        model: str,
        value: {
            response: str,
            data: {
                data1: value1
                data2: value2
                ...
            }
        }
    }
}
{ // El cliente envia un AUDIO_PROMPT y el servidor responde con la transcripcion mientras genera la respuesta
    type: "PROMPT_TRANSCRIPTION",
    data: {
        id: uuid,
        model: str,
        value: ...
    }
}
{ // Una vez ha enviado la respuesta y la transcripcion, cuando tiene el audio TTS, lo envia para que se reproduzca en el navegador
    type: "AUDIO_RESPONSE",
    data: {
        id: uuid,
        model: str,
        speaker: str,
        audio: [int16],
        sampleRate: int
    }
}
Mensajes sobre la API de faceprints:
{
    "type": "FACEPRINT_EVENT",
    "data": {
        "event": "CREATE" | "DELETE" | "UPDATE",
        "name": name
    }
}

CLIENTE => SERVIDOR
Prompt del cliente:
{ // prompt de texto
    type: "PROMPT",
    data: {
        id: uuid,
        chatId: uuid,
        wantTts: bool,
        value: ...
    },
};
{ // prompt de audio
    type: "AUDIO_PROMPT",
    data: {
        id: uuid,
        chatId: uuid,
        wantTts: bool,
        audio: [int16],
        sampleRate: int
    }
}
{ // prompt de audio
    type: "TRANSCRIPTION_REQUEST",
    data: {
        id: uuid,
        audio: [int16],
        sampleRate: int
    }
}

Se puede mejorar con streaming

üéØ Flujo propuesto:
Usuario graba y env√≠a audio (por WebSocket o REST).
Servidor transcribe el audio con STT (e.g. Whisper).
Env√≠a PROMPT_TRANSCRIPTION ‚Üí el frontend muestra el mensaje del usuario.
Servidor llama al LLM para generar la respuesta textual.
Env√≠a RESPONSE ‚Üí el frontend muestra la respuesta textual del LLM.
Servidor sintetiza audio con TTS.
Env√≠a AUDIO_RESPONSE ‚Üí el frontend reproduce el audio autom√°ticamente.


los mensajes isHuman:

Al enviar texto, se tiene solo id y value.
Cuando llega la respuesta del llm, se a√±ade intent.

Si se envia con audio, se tiene solo id, y sampleRate.
Cuando llega la respuesta del stt, se a√±ade value y sttModel.
Cuando llega la respuesta del llm, se a√±ade intent.

Los mensajes not isHuman:

Cuando llega la respuesta, se tiene id, method, provider, model y value.
Si se usa tts, se a√±ade audio y sampleRate.